---
title: "Why I like XPath, XML and HTML"
date: '2022-04-07'
tags:
  - XML
  - xml2
  - XPath
slug: xml-xpath
output: hugodown::hugo_document
---

One of my favorite tool is XPath, the query language for exploring XML and HTML trees.
In this post, I will highlight a few use cases and hope to convince you that it's an awesome thing to know about and play with.

## Brief intro to XPath in R

Say I have some XML,

```{r}
my_xml <- xml2::read_xml("<wrapper><thing>blop</thing></wrapper>")
```

I'm using xml2, by Hadley Wickham, Jim Hester and Jeroen Ooms. 
This package is recommended over the XML package by e.g. the [rOpenSci dev guide](https://devguide.ropensci.org/building.html#recommended-scaffolding).

With XPath I can query the thing element:

```{r}
xml2::xml_find_all(my_xml, ".//thing")
```

I can extract its content via `xml2::xml_text()`:

```{r}
xml2::xml_find_all(my_xml, ".//thing") |>
  xml2::xml_text()
```

I could also [replace the element](https://blog.r-hub.io/2020/01/22/mutable-api/#exposing-the-c-api-in-xml2).

Now, that was an especially simple XPath query. 
XPath's strength is to allow you to really take advantage of the structure of the XML or HTML tree.
With the help of a search engine (or without), you can extract nodes based on their attributes, on their parents, etc.
Note that if you are handling HTML, you might enjoy [selectr by  Simon Potter](https://sjp.co.nz/projects/selectr/) that creates XPath filters based on CSS selectors.

It's really empowering. In the rest of this post, I'll highlight places where this is useful.

## When life gives you XML or HTML

### Web scraping

At the beginning of this blog I liked extracting data from websites.
I did that with [regular expressions](/2017/03/07/blinddates/).
Now I know better and would [wrangle HTML as HTML](/2021/01/15/beanie-baby/).
Goodbye, `stringr::str_detect()`, hello, `xml2::xml_find_all()`.

### pkgdown

If you use pkgdown to produce the documentation website of for your package, 
please know that part of its magic comes from various "HTML tweaks" that are powered by XPath, see for instance ["tweak-reference.R"](https://github.com/r-lib/pkgdown/blob/98d5a5c735eb244cb98b2e6bab1d54bb27c0af95/R/tweak-reference.R#L1).

## When life gives you something else...

You can still make it XML to handle it as such, with XPath!

### Markdown manipulation with commonmark, tinkr

The commonmark package transforms Markdown to XML.
This can be extremely handy to get data [on R Markdown or Markdown files](https://ropensci.org/blog/2018/09/05/commonmark/).

Now, say you want to modify the Markdown file as XML then get a Markdown file back.
It is also possible, with the [tinkr package](https://docs.ropensci.org/tinkr/), started by yours truly, now maintained by Zhian Kamvar.
The conversion back to Markdown relies on [xslt](https://docs.ropensci.org/xslt/) by Jeroen Ooms, a package that can use XSL stylesheets.

### Code tree manipulation with xmlparsedata

Imagine you're writing a domain-specific language where you let users write something like

```r
str_detect(str_to_lower(itemTitle), 'wikidata')
```

that you want to somehow translate to:

```sparql
REGEX(LCASE(?itemTitle),"wikidata")
```

Yes, that's a real use case, from the [glitter package (SPARQL DSL) maintained by Lise Vaudor](https://lvaudor.github.io/glitter/articles/internals.html).

The way we translate the code is to transform it to an XML tree via [Gábor Csárdi's xmlparsedata](https://r-lib.github.io/xmlparsedata/), then we can apply different tweaks based on XPath.

```{r}
parse(
  text = "str_detect(str_to_lower(itemTitle), 'wikidata')",
  keep.source = TRUE
) |> 
  xmlparsedata::xml_parse_data(pretty = TRUE) |> 
  xml2::read_xml() |>
  as.character() |>
  cat()
``` 

To me, having an XML tree at hand makes it easier to think of, and work with, an "abstract syntax tree".

### Data documentation with EML

No matter what format your data is, you can create its metadata using the [EML package](https://docs.ropensci.org/EML/) that creates XML metadata following the Ecological Metadata Language.
Sure, you might prefer using [dataspice](https://docs.ropensci.org/dataspice/) (and get JSON).

## Conclusion

In this post I've explained why I find XPath, XML, HTML so useful.
Applications are endless, not limited to the examples from this post: web scraping, pkgdown tweaks, Markdown manipulation, code tree manipulation...


